<?xml version="1.0" encoding="UTF-8"?>
<zabbix_export>
  <version>5.0</version>
  <date>2021-11-09T05:11:58Z</date>
  <groups>
    <group>
      <name>Clickhouse servers</name>
    </group>
  </groups>
  <templates>
    <template>
      <template>Clickhouse</template>
      <name>Clickhouse</name>
      <description>## Overview Clickhouse Template + monitoring script which covered the following aspects of monitoring: * Memory Tracking * Select speed * Insert / Merge speed * How many parts in partitions * Replication * Zookeeper communications * Distributed tables server-server connection * DNS Cache Contains **33 items, 15 triggers, 10 graphs, and 1 host screen** Require **clickhouse-client** and **zbx\_clickhouse\_monitor.sh** installed on zabbix-agent host ![Clickhouse Zabbix Template](https://github.com/Altinity/clickhouse-zabbix-template/raw/master/img/dashboard.png)</description>
      <groups>
        <group>
          <name>Clickhouse servers</name>
        </group>
      </groups>
      <applications>
        <application>
          <name>Clickhouse</name>
        </application>
      </applications>
      <items>
        <item>
          <name>delayed insert queries</name>
          <key>ch_params[DelayedInserts]</key>
          <delay>30s</delay>
          <applications>
            <application>
              <name>Clickhouse</name>
            </application>
          </applications>
          <preprocessing>
            <step>
              <type>SIMPLE_CHANGE</type>
              <params></params>
            </step>
          </preprocessing>
          <triggers>
            <trigger>
              <expression>{last()} > 0</expression>
              <name>{HOST.HOST} have INSERT queries that are throttled due to high number of active data parts for partition in a MergeTree, please decrease INSERT frequency</name>
              <url>https://clickhouse.tech/docs/en/development/architecture/#merge-tree</url>
              <priority>DISASTER</priority>
              <description>INSERT queries that are throttled due to high number of active data parts for partition in a MergeTree table.</description>
            </trigger>
          </triggers>
        </item>
        <item>
          <name>data directory size</name>
          <key>ch_params[DiskUsage]</key>
          <delay>30s</delay>
          <units>B</units>
          <applications>
            <application>
              <name>Clickhouse</name>
            </application>
          </applications>
        </item>
        <item>
          <name>distributed connection fail after all retries finished</name>
          <key>ch_params[DistributedConnectionFailAtAll]</key>
          <delay>30s</delay>
          <applications>
            <application>
              <name>Clickhouse</name>
            </application>
          </applications>
          <preprocessing>
            <step>
              <type>SIMPLE_CHANGE</type>
              <params></params>
            </step>
          </preprocessing>
        </item>
        <item>
          <name>distributed connection fail with retry</name>
          <key>ch_params[DistributedConnectionFailTry]</key>
          <delay>30s</delay>
          <applications>
            <application>
              <name>Clickhouse</name>
            </application>
          </applications>
          <preprocessing>
            <step>
              <type>SIMPLE_CHANGE</type>
              <params></params>
            </step>
          </preprocessing>
        </item>
        <item>
          <name>distributed pending files</name>
          <key>ch_params[DistributedFilesToInsert]</key>
          <delay>30s</delay>
          <description>Number of pending files to process for asynchronous insertion into Distributed tables. Number of files for every shard is summed.</description>
          <applications>
            <application>
              <name>Clickhouse</name>
            </application>
          </applications>
        </item>
        <item>
          <name>distributed connections</name>
          <key>ch_params[DistributedSend]</key>
          <delay>30s</delay>
          <applications>
            <application>
              <name>Clickhouse</name>
            </application>
          </applications>
        </item>
        <item>
          <name>current HTTP connections</name>
          <key>ch_params[HTTPConnection]</key>
          <delay>30s</delay>
          <applications>
            <application>
              <name>Clickhouse</name>
            </application>
          </applications>
          <triggers>
            <trigger>
              <expression>{last()} >= {$MAX_HTTP_CONNECTIONS}</expression>
              <name>{HOST.HOST} HTTP connections >= {$MAX_HTTP_CONNECTIONS}</name>
              <url>https://clickhouse.tech/docs/en/operations/server_settings/settings/#max-concurrent-queries</url>
              <priority>WARNING</priority>
              <description>The clickhouse is adapted to run not a very large number of parallel requests, not every HTTP connection means a running sql request, but a large number of open tcp connections can cause a spike in sudden sql requests, resulting in performance degradation.</description>
            </trigger>
          </triggers>
        </item>
        <item>
          <name>inserted bytes per second</name>
          <key>ch_params[InsertedBytes]</key>
          <delay>30s</delay>
          <units>B</units>
          <applications>
            <application>
              <name>Clickhouse</name>
            </application>
          </applications>
          <preprocessing>
            <step>
              <type>CHANGE_PER_SECOND</type>
              <params></params>
            </step>
          </preprocessing>
        </item>
        <item>
          <name>inserted rows per second</name>
          <key>ch_params[InsertedRows]</key>
          <delay>30s</delay>
          <applications>
            <application>
              <name>Clickhouse</name>
            </application>
          </applications>
          <preprocessing>
            <step>
              <type>CHANGE_PER_SECOND</type>
              <params></params>
            </step>
          </preprocessing>
        </item>
        <item>
          <name>processed INSERT queries</name>
          <key>ch_params[InsertQuery]</key>
          <delay>30s</delay>
          <applications>
            <application>
              <name>Clickhouse</name>
            </application>
          </applications>
          <preprocessing>
            <step>
              <type>SIMPLE_CHANGE</type>
              <params></params>
            </step>
          </preprocessing>
        </item>
        <item>
          <name>the longest currently running query time</name>
          <key>ch_params[LongestRunningQuery]</key>
          <delay>30s</delay>
          <value_type>FLOAT</value_type>
          <units>s</units>
          <applications>
            <application>
              <name>Clickhouse</name>
            </application>
          </applications>
          <triggers>
            <trigger>
              <expression>{last()} >= {$MAX_QUERY_TIME}</expression>
              <name>{HOST.HOST} have queries which running more than {$MAX_QUERY_TIME} sec</name>
              <priority>WARNING</priority>
              <manual_close>YES</manual_close>
            </trigger>
          </triggers>
        </item>
        <item>
          <name>max count of parts per partition across all tables</name>
          <key>ch_params[MaxPartCountForPartition]</key>
          <delay>30s</delay>
          <applications>
            <application>
              <name>Clickhouse</name>
            </application>
          </applications>
          <triggers>
            <trigger>
              <expression>{last()} >= {$MAX_PARTS_PER_PARTITION} * 0.9</expression>
              <name>{HOST.HOST} MergeTree parts 90% of {$MAX_PARTS_PER_PARTITION}, please descease INSERT queries frequency</name>
              <priority>HIGH</priority>
              <description>Clickhouse MergeTree table engine split each INSERT query to partitions (PARTITION BY expression) and add one or more PARTS per INSERT inside each partition, after that background merge process run, and when you have too much unmerged parts inside partition, SELECT queries performance can significate degrade, so clickhouse try delay insert, or abort it</description>
            </trigger>
          </triggers>
        </item>
        <item>
          <name>memory for background merges</name>
          <key>ch_params[MemoryTrackingForMerges]</key>
          <delay>30s</delay>
          <units>B</units>
          <description>Total amount of memory (bytes) allocated for background merges. Included in MemoryTrackingInBackgroundProcessingPool. Note that this value may include a drift when the memory was allocated in a context of background processing pool and freed in other context or vice-versa. This happens naturally due to caches for tables indexes and doesn't indicate memory leaks.</description>
          <applications>
            <application>
              <name>Clickhouse</name>
            </application>
          </applications>
        </item>
        <item>
          <name>memory for backround moves</name>
          <key>ch_params[MemoryTrackingInBackgroundMoveProcessingPool]</key>
          <delay>30s</delay>
          <units>B</units>
          <description>Total amount of memory (bytes) allocated in background processing pool (that is dedicated for backround moves). Note that this value may include a drift when the memory was allocated in a context of background processing pool and freed in other context or vice-versa. This happens naturally due to caches for tables indexes and doesn't indicate memory leaks.</description>
          <applications>
            <application>
              <name>Clickhouse</name>
            </application>
          </applications>
        </item>
        <item>
          <name>memory for background merges, mutations and fetches.</name>
          <key>ch_params[MemoryTrackingInBackgroundProcessingPool]</key>
          <delay>30s</delay>
          <units>B</units>
          <description>Total amount of memory (bytes) allocated in background processing pool (that is dedicated for backround merges, mutations and fetches). Note that this value may include a drift when the memory was allocated in a context of background processing pool and freed in other context or vice-versa. This happens naturally due to caches for tables indexes and doesn't indicate memory leaks.</description>
          <applications>
            <application>
              <name>Clickhouse</name>
            </application>
          </applications>
        </item>
        <item>
          <name>memory for bookkeeping tasks of Replicated tables.</name>
          <key>ch_params[MemoryTrackingInBackgroundSchedulePool]</key>
          <delay>30s</delay>
          <units>B</units>
          <description>Total amount of memory (bytes) allocated in background schedule pool (that is dedicated for bookkeeping tasks of Replicated tables).</description>
          <applications>
            <application>
              <name>Clickhouse</name>
            </application>
          </applications>
        </item>
        <item>
          <name>memory used by queries</name>
          <key>ch_params[MemoryTracking]</key>
          <delay>30s</delay>
          <units>B</units>
          <applications>
            <application>
              <name>Clickhouse</name>
            </application>
          </applications>
        </item>
        <item>
          <name>merged rows per second</name>
          <key>ch_params[MergedRows]</key>
          <delay>30s</delay>
          <applications>
            <application>
              <name>Clickhouse</name>
            </application>
          </applications>
          <preprocessing>
            <step>
              <type>CHANGE_PER_SECOND</type>
              <params></params>
            </step>
          </preprocessing>
        </item>
        <item>
          <name>merged uncompressed bytes per second</name>
          <key>ch_params[MergedUncompressedBytes]</key>
          <delay>30s</delay>
          <units>B</units>
          <applications>
            <application>
              <name>Clickhouse</name>
            </application>
          </applications>
          <preprocessing>
            <step>
              <type>CHANGE_PER_SECOND</type>
              <params></params>
            </step>
          </preprocessing>
        </item>
        <item>
          <name>current MySQL connections</name>
          <key>ch_params[MySQLConnection]</key>
          <delay>30s</delay>
          <applications>
            <application>
              <name>Clickhouse</name>
            </application>
          </applications>
          <triggers>
            <trigger>
              <expression>{last()} >= {$MAX_MYSQL_CONNECTIONS}</expression>
              <name>{HOST.HOST} MySQL connections >= {$MAX_MYSQL_CONNECTIONS}</name>
              <url>https://clickhouse.tech/docs/en/operations/server_settings/settings/#max-concurrent-queries</url>
              <priority>WARNING</priority>
              <description>The clickhouse is adapted to run not a very large number of parallel requests, not every MySQL connection means a running sql request, but a large number of open tcp connections can cause a spike in sudden sql requests, resulting in performance degradation.</description>
            </trigger>
          </triggers>
        </item>
        <item>
          <name>network errors, i.e. DNS resolve</name>
          <key>ch_params[NetworkErrors]</key>
          <delay>30s</delay>
          <applications>
            <application>
              <name>Clickhouse</name>
            </application>
          </applications>
          <preprocessing>
            <step>
              <type>SIMPLE_CHANGE</type>
              <params></params>
            </step>
          </preprocessing>
          <triggers>
            <trigger>
              <expression>{last()} > 0</expression>
              <name>{HOST.HOST} clickhouse DNS errors occured</name>
              <priority>WARNING</priority>
              <description>Please check DNS settings and remote_servers part of /etc/clickhouse-server/ https://clickhouse.tech/docs/en/operations/server_settings/settings/#server_settings_remote_servers https://clickhouse.tech/docs/en/operations/server_settings/settings/#server-settings-disable_internal_dns_cache https://clickhouse.tech/docs/en/query_language/system/#query_language-system-drop-dns-cache</description>
              <manual_close>YES</manual_close>
            </trigger>
          </triggers>
        </item>
        <item>
          <name>current running queries</name>
          <key>ch_params[Query]</key>
          <delay>30s</delay>
          <applications>
            <application>
              <name>Clickhouse</name>
            </application>
          </applications>
          <triggers>
            <trigger>
              <expression>{last(3m)} >= 0.9 * {$MAX_CONCURRENT_QUERIES}</expression>
              <name>{HOST.HOST} running queries 90% of {$MAX_CONCURRENT_QUERIES}</name>
              <url>https://clickhouse.tech/docs/en/operations/server_settings/settings/#max-concurrent-queries</url>
              <priority>HIGH</priority>
              <description>Each concurrent SELECT query use memory in JOINs use CPU for running aggregation function and can read lot of data from disk when scan parts in partitions and utilize disk IO. Each concurrent INSERT query, allocate around 1MB per each column in an inserted table and can utilize disk IO. Look at following documentation parts https://clickhouse.tech/docs/en/operations/settings/query_complexity/ https://clickhouse.tech/docs/en/operations/quotas/</description>
              <manual_close>YES</manual_close>
            </trigger>
          </triggers>
        </item>
        <item>
          <name>read bytes per second</name>
          <key>ch_params[ReadCompressedBytes]</key>
          <delay>30s</delay>
          <units>B</units>
          <applications>
            <application>
              <name>Clickhouse</name>
            </application>
          </applications>
          <preprocessing>
            <step>
              <type>CHANGE_PER_SECOND</type>
              <params></params>
            </step>
          </preprocessing>
        </item>
        <item>
          <name>Read-Only Replicas</name>
          <key>ch_params[ReadonlyReplica]</key>
          <delay>30s</delay>
          <applications>
            <application>
              <name>Clickhouse</name>
            </application>
          </applications>
          <triggers>
            <trigger>
              <expression>{last()} > 0</expression>
              <name>{HOST.HOST} have read-only replicated tables, check Zookeeper state</name>
              <url>https://clickhouse.tech/docs/en/operations/table_engines/replication/#recovery-after-failures</url>
              <priority>DISASTER</priority>
              <description>Number of Replicated tables that are currently in readonly state due to re-initialization after ZooKeeper session loss or due to startup without ZooKeeper configured.</description>
            </trigger>
          </triggers>
        </item>
        <item>
          <name>read, pread, io_getevents, etc. syscalls in fly</name>
          <key>ch_params[Read]</key>
          <delay>30s</delay>
          <applications>
            <application>
              <name>Clickhouse</name>
            </application>
          </applications>
        </item>
        <item>
          <name>replica partial shutdown</name>
          <key>ch_params[ReplicaPartialShutdown]</key>
          <delay>30s</delay>
          <description>how many times ReplicatedMergreTree table yield in state when Zookeeper session is expired</description>
          <applications>
            <application>
              <name>Clickhouse</name>
            </application>
          </applications>
          <preprocessing>
            <step>
              <type>SIMPLE_CHANGE</type>
              <params></params>
            </step>
          </preprocessing>
        </item>
        <item>
          <name>replication lag across all tables</name>
          <key>ch_params[ReplicasMaxAbsoluteDelay]</key>
          <delay>30s</delay>
          <units>s</units>
          <applications>
            <application>
              <name>Clickhouse</name>
            </application>
          </applications>
          <triggers>
            <trigger>
              <expression>{last(3m)} >= {$MAX_REPLICA_DELAY_DISTIBUTED_QUERIES}</expression>
              <name>{HOST.HOST} have replication lag more {$MAX_REPLICA_DELAY_DISTIBUTED_QUERIES} sec</name>
              <url>https://clickhouse.tech/docs/en/operations/settings/settings/#settings-max_replica_delay_for_distributed_queries</url>
              <priority>HIGH</priority>
              <description>When replica have too much lag, it can be skipped from Distributed SELECT Queries without errors and you will have wrong query results Check disks and networks on monitoring servers</description>
              <manual_close>YES</manual_close>
            </trigger>
          </triggers>
        </item>
        <item>
          <name>replication tasks in queue</name>
          <key>ch_params[ReplicasSumQueueSize]</key>
          <delay>30s</delay>
          <applications>
            <application>
              <name>Clickhouse</name>
            </application>
          </applications>
        </item>
        <item>
          <name>revision</name>
          <key>ch_params[Revision]</key>
          <delay>30s</delay>
          <applications>
            <application>
              <name>Clickhouse</name>
            </application>
          </applications>
          <triggers>
            <trigger>
              <expression>{change()}=1</expression>
              <name>{HOST.HOST} clickhouse version changed</name>
              <priority>WARNING</priority>
            </trigger>
          </triggers>
        </item>
        <item>
          <name>parts read from disk per second</name>
          <key>ch_params[SelectedParts]</key>
          <delay>30s</delay>
          <applications>
            <application>
              <name>Clickhouse</name>
            </application>
          </applications>
          <preprocessing>
            <step>
              <type>CHANGE_PER_SECOND</type>
              <params></params>
            </step>
          </preprocessing>
        </item>
        <item>
          <name>processed SELECT queries</name>
          <key>ch_params[SelectQuery]</key>
          <delay>30s</delay>
          <applications>
            <application>
              <name>Clickhouse</name>
            </application>
          </applications>
          <preprocessing>
            <step>
              <type>SIMPLE_CHANGE</type>
              <params></params>
            </step>
          </preprocessing>
        </item>
        <item>
          <name>current TCP connections</name>
          <key>ch_params[TCPConnection]</key>
          <delay>30s</delay>
          <applications>
            <application>
              <name>Clickhouse</name>
            </application>
          </applications>
          <triggers>
            <trigger>
              <expression>{last()} >= {$MAX_TCP_CONNECTIONS}</expression>
              <name>{HOST.HOST} TCP connections >= {$MAX_TCP_CONNECTIONS}</name>
              <url>https://clickhouse.tech/docs/en/operations/server_settings/settings/#max-connections</url>
              <priority>WARNING</priority>
              <description>The clickhouse is adapted to run not a very large number of parallel requests, not every tcp connection means a running sql request, but a large number of open tcp connections can cause a spike in sudden sql requests, resulting in performance degradation.</description>
            </trigger>
          </triggers>
        </item>
        <item>
          <name>clickhouse-server uptime</name>
          <key>ch_params[Uptime]</key>
          <delay>30s</delay>
          <units>s</units>
          <applications>
            <application>
              <name>Clickhouse</name>
            </application>
          </applications>
          <triggers>
            <trigger>
              <expression>{nodata(3m)}</expression>
              <name>{HOST.HOST} clickhouse-server monitoring have no data, possible clickhouse-server is down, check `systemd status clickhouse-server` and check zbx_clickhouse_monitor.sh and `systemd status zabbix-agent`</name>
              <priority>HIGH</priority>
              <manual_close>YES</manual_close>
            </trigger>
            <trigger>
              <expression>{last()} &lt;= 600</expression>
              <name>{HOST.HOST} clickhouse-server recently restated</name>
              <priority>WARNING</priority>
              <manual_close>YES</manual_close>
            </trigger>
          </triggers>
        </item>
        <item>
          <name>write, pwrite, io_getevents, etc. syscalls in fly</name>
          <key>ch_params[Write]</key>
          <delay>30s</delay>
          <applications>
            <application>
              <name>Clickhouse</name>
            </application>
          </applications>
        </item>
        <item>
          <name>Hardware exceptions in communication with ZooKeeper server</name>
          <key>ch_params[ZooKeeperHardwareExceptions]</key>
          <delay>30s</delay>
          <applications>
            <application>
              <name>Clickhouse</name>
            </application>
          </applications>
          <preprocessing>
            <step>
              <type>SIMPLE_CHANGE</type>
              <params></params>
            </step>
          </preprocessing>
        </item>
        <item>
          <name>Other exceptions in communication with ZooKeeper server</name>
          <key>ch_params[ZooKeeperOtherExceptions]</key>
          <delay>30s</delay>
          <applications>
            <application>
              <name>Clickhouse</name>
            </application>
          </applications>
          <preprocessing>
            <step>
              <type>SIMPLE_CHANGE</type>
              <params></params>
            </step>
          </preprocessing>
        </item>
        <item>
          <name>User exceptions in communication with ZooKeeper server</name>
          <key>ch_params[ZooKeeperUserExceptions]</key>
          <delay>30s</delay>
          <applications>
            <application>
              <name>Clickhouse</name>
            </application>
          </applications>
          <preprocessing>
            <step>
              <type>SIMPLE_CHANGE</type>
              <params></params>
            </step>
          </preprocessing>
        </item>
        <item>
          <name>number of watches in zookeeper</name>
          <key>ch_params[ZooKeeperWatch]</key>
          <delay>30s</delay>
          <applications>
            <application>
              <name>Clickhouse</name>
            </application>
          </applications>
        </item>
      </items>
      <macros>
        <macro>
          <macro>{$MAX_CONCURENT_QUERIES}</macro>
          <value>100</value>
        </macro>
        <macro>
          <macro>{$MAX_DELAYED_FILES_TO_DISTRIBUTED_INSERT}</macro>
          <value>50</value>
        </macro>
        <macro>
          <macro>{$MAX_HTTP_CONNECTIONS}</macro>
          <value>100</value>
        </macro>
        <macro>
          <macro>{$MAX_MYSQL_CONNECTIONS}</macro>
          <value>100</value>
        </macro>
        <macro>
          <macro>{$MAX_PARTS_PER_PARTITION}</macro>
          <value>300</value>
        </macro>
        <macro>
          <macro>{$MAX_QUERY_TIME}</macro>
          <value>600</value>
        </macro>
        <macro>
          <macro>{$MAX_REPLICA_DELAY_DISTIBUTED_QUERIES}</macro>
          <value>300</value>
        </macro>
        <macro>
          <macro>{$MAX_TCP_CONNECTIONS}</macro>
          <value>1024</value>
        </macro>
        <macro>
          <macro>{$MIN_INSERTED_ROWS_PER_QUERY}</macro>
          <value>1000</value>
        </macro>
      </macros>
      <screens>
        <screen>
          <name>Clickhouse metrics</name>
          <hsize>2</hsize>
          <vsize>5</vsize>
          <screen_items>
            <screen_item>
              <resourcetype>0</resourcetype>
              <style>0</style>
              <resource>
                <name>Concurrent running queries</name>
                <host>Clickhouse</host>
              </resource>
              <width>450</width>
              <height>100</height>
              <x>0</x>
              <y>0</y>
              <colspan>1</colspan>
              <rowspan>1</rowspan>
              <elements>0</elements>
              <valign>0</valign>
              <halign>0</halign>
              <dynamic>0</dynamic>
              <sort_triggers>0</sort_triggers>
              <url></url>
              <application></application>
              <max_columns>3</max_columns>
            </screen_item>
            <screen_item>
              <resourcetype>0</resourcetype>
              <style>0</style>
              <resource>
                <name>Write / Merge bytes/sec</name>
                <host>Clickhouse</host>
              </resource>
              <width>450</width>
              <height>100</height>
              <x>1</x>
              <y>0</y>
              <colspan>1</colspan>
              <rowspan>1</rowspan>
              <elements>0</elements>
              <valign>0</valign>
              <halign>0</halign>
              <dynamic>0</dynamic>
              <sort_triggers>0</sort_triggers>
              <url></url>
              <application></application>
              <max_columns>3</max_columns>
            </screen_item>
            <screen_item>
              <resourcetype>0</resourcetype>
              <style>0</style>
              <resource>
                <name>Finished Queries</name>
                <host>Clickhouse</host>
              </resource>
              <width>450</width>
              <height>100</height>
              <x>0</x>
              <y>1</y>
              <colspan>1</colspan>
              <rowspan>1</rowspan>
              <elements>0</elements>
              <valign>0</valign>
              <halign>0</halign>
              <dynamic>0</dynamic>
              <sort_triggers>0</sort_triggers>
              <url></url>
              <application></application>
              <max_columns>3</max_columns>
            </screen_item>
            <screen_item>
              <resourcetype>0</resourcetype>
              <style>0</style>
              <resource>
                <name>Insert / Merge rows/sec</name>
                <host>Clickhouse</host>
              </resource>
              <width>450</width>
              <height>100</height>
              <x>1</x>
              <y>1</y>
              <colspan>1</colspan>
              <rowspan>1</rowspan>
              <elements>0</elements>
              <valign>0</valign>
              <halign>0</halign>
              <dynamic>0</dynamic>
              <sort_triggers>0</sort_triggers>
              <url></url>
              <application></application>
              <max_columns>3</max_columns>
            </screen_item>
            <screen_item>
              <resourcetype>0</resourcetype>
              <style>0</style>
              <resource>
                <name>Memory Usage</name>
                <host>Clickhouse</host>
              </resource>
              <width>500</width>
              <height>100</height>
              <x>0</x>
              <y>2</y>
              <colspan>1</colspan>
              <rowspan>1</rowspan>
              <elements>0</elements>
              <valign>0</valign>
              <halign>0</halign>
              <dynamic>0</dynamic>
              <sort_triggers>0</sort_triggers>
              <url></url>
              <application></application>
              <max_columns>3</max_columns>
            </screen_item>
            <screen_item>
              <resourcetype>0</resourcetype>
              <style>0</style>
              <resource>
                <name>Database size</name>
                <host>Clickhouse</host>
              </resource>
              <width>500</width>
              <height>100</height>
              <x>1</x>
              <y>2</y>
              <colspan>1</colspan>
              <rowspan>1</rowspan>
              <elements>0</elements>
              <valign>0</valign>
              <halign>0</halign>
              <dynamic>0</dynamic>
              <sort_triggers>0</sort_triggers>
              <url></url>
              <application></application>
              <max_columns>3</max_columns>
            </screen_item>
            <screen_item>
              <resourcetype>0</resourcetype>
              <style>0</style>
              <resource>
                <name>Connections</name>
                <host>Clickhouse</host>
              </resource>
              <width>450</width>
              <height>100</height>
              <x>0</x>
              <y>3</y>
              <colspan>1</colspan>
              <rowspan>1</rowspan>
              <elements>0</elements>
              <valign>0</valign>
              <halign>0</halign>
              <dynamic>0</dynamic>
              <sort_triggers>0</sort_triggers>
              <url></url>
              <application></application>
              <max_columns>3</max_columns>
            </screen_item>
            <screen_item>
              <resourcetype>0</resourcetype>
              <style>0</style>
              <resource>
                <name>Distributed</name>
                <host>Clickhouse</host>
              </resource>
              <width>450</width>
              <height>100</height>
              <x>1</x>
              <y>3</y>
              <colspan>1</colspan>
              <rowspan>1</rowspan>
              <elements>0</elements>
              <valign>0</valign>
              <halign>0</halign>
              <dynamic>0</dynamic>
              <sort_triggers>0</sort_triggers>
              <url></url>
              <application></application>
              <max_columns>3</max_columns>
            </screen_item>
            <screen_item>
              <resourcetype>0</resourcetype>
              <style>0</style>
              <resource>
                <name>Replication</name>
                <host>Clickhouse</host>
              </resource>
              <width>450</width>
              <height>100</height>
              <x>0</x>
              <y>4</y>
              <colspan>1</colspan>
              <rowspan>1</rowspan>
              <elements>0</elements>
              <valign>0</valign>
              <halign>0</halign>
              <dynamic>0</dynamic>
              <sort_triggers>0</sort_triggers>
              <url></url>
              <application></application>
              <max_columns>3</max_columns>
            </screen_item>
            <screen_item>
              <resourcetype>0</resourcetype>
              <style>0</style>
              <resource>
                <name>Zookeeper</name>
                <host>Clickhouse</host>
              </resource>
              <width>450</width>
              <height>100</height>
              <x>1</x>
              <y>4</y>
              <colspan>1</colspan>
              <rowspan>1</rowspan>
              <elements>0</elements>
              <valign>0</valign>
              <halign>0</halign>
              <dynamic>0</dynamic>
              <sort_triggers>0</sort_triggers>
              <url></url>
              <application></application>
              <max_columns>3</max_columns>
            </screen_item>
          </screen_items>
        </screen>
      </screens>
    </template>
  </templates>
  <triggers>
    <trigger>
      <expression>{Clickhouse:ch_params[DistributedConnectionFailAtAll].last()}>=0 or {Clickhouse:ch_params[DistributedConnectionFailTry].last()}>=0 or {Clickhouse:ch_params[DistributedFilesToInsert].last()}>={$MAX_DELAYED_FILES_TO_DISTRIBUTED_INSERT}</expression>
      <name>{HOST.HOST} distributed connection exceptions occured</name>
      <url>https://clickhouse.tech/docs/en/operations/table_engines/distributed/</url>
      <priority>AVERAGE</priority>
      <description>please check communications between Clickhouse servers and &lt;remote_servers> in config.xml https://clickhouse.tech/docs/en/operations/table_engines/distributed/ https://clickhouse.tech/docs/en/query_language/system/#query_language-system-distributed https://clickhouse.tech/docs/en/operations/server_settings/settings/#server_settings_remote_servers When you insert data to distributed table. Data is written to target *MergreTree tables asynchronously. When inserted in the table, the data block is just written to the local file system. The data is sent to the remote servers in the background as soon as possible. The period for sending data is managed by the distributed_directory_monitor_sleep_time_ms and distributed_directory_monitor_max_sleep_time_ms settings. The Distributed engine sends each file with inserted data separately, but you can enable batch sending of files with the distributed_directory_monitor_batch_inserts setting.</description>
    </trigger>
    <trigger>
      <expression>{Clickhouse:ch_params[InsertQuery].last()}>0 and ( {Clickhouse:ch_params[InsertedRows].last()} / {Clickhouse:ch_params[InsertQuery].last()} ) &lt;= {$MIN_INSERTED_ROWS_PER_QUERY}</expression>
      <name>{HOST.HOST} please increase inserted rows per INSERT query</name>
      <url>https://clickhouse.tech/docs/en/introduction/performance/#performance-when-inserting-data</url>
      <priority>HIGH</priority>
      <description>Clickhouse team recommends inserting data in packets of at least 1000 rows or no more than a single request per second. Please use Buffer table https://clickhouse.tech/docs/en/operations/table_engines/buffer/ or https://github.com/nikepan/clickhouse-bulk</description>
    </trigger>
  </triggers>
  <graphs>
    <graph>
      <name>Concurrent running queries</name>
      <width>600</width>
      <show_work_period>NO</show_work_period>
      <ymin_type_1>FIXED</ymin_type_1>
      <graph_items>
        <graph_item>
          <color>DDDD00</color>
          <calc_fnc>MAX</calc_fnc>
          <item>
            <host>Clickhouse</host>
            <key>ch_params[Write]</key>
          </item>
        </graph_item>
        <graph_item>
          <sortorder>1</sortorder>
          <color>00BB00</color>
          <calc_fnc>MAX</calc_fnc>
          <item>
            <host>Clickhouse</host>
            <key>ch_params[Read]</key>
          </item>
        </graph_item>
        <graph_item>
          <sortorder>2</sortorder>
          <color>BB0000</color>
          <calc_fnc>MAX</calc_fnc>
          <item>
            <host>Clickhouse</host>
            <key>ch_params[Query]</key>
          </item>
        </graph_item>
        <graph_item>
          <sortorder>3</sortorder>
          <color>A54F10</color>
          <yaxisside>RIGHT</yaxisside>
          <item>
            <host>Clickhouse</host>
            <key>ch_params[LongestRunningQuery]</key>
          </item>
        </graph_item>
      </graph_items>
    </graph>
    <graph>
      <name>Connections</name>
      <width>600</width>
      <ymin_type_1>FIXED</ymin_type_1>
      <graph_items>
        <graph_item>
          <color>1A7C11</color>
          <item>
            <host>Clickhouse</host>
            <key>ch_params[TCPConnection]</key>
          </item>
        </graph_item>
        <graph_item>
          <sortorder>1</sortorder>
          <color>F63100</color>
          <item>
            <host>Clickhouse</host>
            <key>ch_params[HTTPConnection]</key>
          </item>
        </graph_item>
        <graph_item>
          <sortorder>2</sortorder>
          <color>CCCC00</color>
          <item>
            <host>Clickhouse</host>
            <key>ch_params[MySQLConnection]</key>
          </item>
        </graph_item>
        <graph_item>
          <sortorder>3</sortorder>
          <color>A54F10</color>
          <item>
            <host>Clickhouse</host>
            <key>ch_params[DistributedSend]</key>
          </item>
        </graph_item>
      </graph_items>
    </graph>
    <graph>
      <name>Database size</name>
      <width>600</width>
      <show_work_period>NO</show_work_period>
      <ymin_type_1>FIXED</ymin_type_1>
      <graph_items>
        <graph_item>
          <color>AA0000</color>
          <item>
            <host>Clickhouse</host>
            <key>ch_params[DiskUsage]</key>
          </item>
        </graph_item>
      </graph_items>
    </graph>
    <graph>
      <name>Distributed</name>
      <ymin_type_1>FIXED</ymin_type_1>
      <graph_items>
        <graph_item>
          <color>CC0000</color>
          <item>
            <host>Clickhouse</host>
            <key>ch_params[DistributedConnectionFailAtAll]</key>
          </item>
        </graph_item>
        <graph_item>
          <sortorder>1</sortorder>
          <color>CCCC00</color>
          <item>
            <host>Clickhouse</host>
            <key>ch_params[DistributedConnectionFailTry]</key>
          </item>
        </graph_item>
        <graph_item>
          <sortorder>2</sortorder>
          <color>00BB00</color>
          <yaxisside>RIGHT</yaxisside>
          <item>
            <host>Clickhouse</host>
            <key>ch_params[DistributedFilesToInsert]</key>
          </item>
        </graph_item>
      </graph_items>
    </graph>
    <graph>
      <name>Finished Queries</name>
      <width>600</width>
      <show_work_period>NO</show_work_period>
      <type>STACKED</type>
      <ymin_type_1>FIXED</ymin_type_1>
      <graph_items>
        <graph_item>
          <color>4CAF50</color>
          <item>
            <host>Clickhouse</host>
            <key>ch_params[SelectQuery]</key>
          </item>
        </graph_item>
        <graph_item>
          <sortorder>1</sortorder>
          <color>DDDD00</color>
          <item>
            <host>Clickhouse</host>
            <key>ch_params[InsertQuery]</key>
          </item>
        </graph_item>
      </graph_items>
    </graph>
    <graph>
      <name>Insert / Merge rows/sec</name>
      <width>600</width>
      <show_work_period>NO</show_work_period>
      <ymin_type_1>FIXED</ymin_type_1>
      <graph_items>
        <graph_item>
          <color>DDDD00</color>
          <item>
            <host>Clickhouse</host>
            <key>ch_params[InsertedRows]</key>
          </item>
        </graph_item>
        <graph_item>
          <sortorder>1</sortorder>
          <color>CC0000</color>
          <item>
            <host>Clickhouse</host>
            <key>ch_params[MergedRows]</key>
          </item>
        </graph_item>
      </graph_items>
    </graph>
    <graph>
      <name>Memory Usage</name>
      <width>600</width>
      <show_work_period>NO</show_work_period>
      <ymin_type_1>FIXED</ymin_type_1>
      <graph_items>
        <graph_item>
          <color>F63100</color>
          <item>
            <host>Clickhouse</host>
            <key>ch_params[MemoryTracking]</key>
          </item>
        </graph_item>
        <graph_item>
          <sortorder>1</sortorder>
          <color>FFFF33</color>
          <item>
            <host>Clickhouse</host>
            <key>ch_params[MemoryTrackingForMerges]</key>
          </item>
        </graph_item>
        <graph_item>
          <sortorder>2</sortorder>
          <color>AAAA00</color>
          <item>
            <host>Clickhouse</host>
            <key>ch_params[MemoryTrackingInBackgroundProcessingPool]</key>
          </item>
        </graph_item>
        <graph_item>
          <sortorder>3</sortorder>
          <color>000099</color>
          <item>
            <host>Clickhouse</host>
            <key>ch_params[MemoryTrackingInBackgroundMoveProcessingPool]</key>
          </item>
        </graph_item>
        <graph_item>
          <sortorder>4</sortorder>
          <color>00DDDD</color>
          <item>
            <host>Clickhouse</host>
            <key>ch_params[MemoryTrackingInBackgroundSchedulePool]</key>
          </item>
        </graph_item>
      </graph_items>
    </graph>
    <graph>
      <name>Replication</name>
      <width>600</width>
      <ymin_type_1>FIXED</ymin_type_1>
      <graph_items>
        <graph_item>
          <color>EE0000</color>
          <item>
            <host>Clickhouse</host>
            <key>ch_params[ReadonlyReplica]</key>
          </item>
        </graph_item>
        <graph_item>
          <sortorder>1</sortorder>
          <color>DDDD00</color>
          <item>
            <host>Clickhouse</host>
            <key>ch_params[ReplicaPartialShutdown]</key>
          </item>
        </graph_item>
        <graph_item>
          <sortorder>2</sortorder>
          <color>2774A4</color>
          <yaxisside>RIGHT</yaxisside>
          <item>
            <host>Clickhouse</host>
            <key>ch_params[ReplicasMaxAbsoluteDelay]</key>
          </item>
        </graph_item>
        <graph_item>
          <sortorder>3</sortorder>
          <color>A54F10</color>
          <item>
            <host>Clickhouse</host>
            <key>ch_params[ReplicasSumQueueSize]</key>
          </item>
        </graph_item>
      </graph_items>
    </graph>
    <graph>
      <name>Write / Merge bytes/sec</name>
      <width>600</width>
      <show_work_period>NO</show_work_period>
      <ymin_type_1>FIXED</ymin_type_1>
      <graph_items>
        <graph_item>
          <color>CCCC00</color>
          <item>
            <host>Clickhouse</host>
            <key>ch_params[InsertedBytes]</key>
          </item>
        </graph_item>
        <graph_item>
          <sortorder>1</sortorder>
          <color>BB0000</color>
          <item>
            <host>Clickhouse</host>
            <key>ch_params[MergedUncompressedBytes]</key>
          </item>
        </graph_item>
      </graph_items>
    </graph>
    <graph>
      <name>Zookeeper</name>
      <width>600</width>
      <show_work_period>NO</show_work_period>
      <ymin_type_1>FIXED</ymin_type_1>
      <graph_items>
        <graph_item>
          <color>FF3333</color>
          <item>
            <host>Clickhouse</host>
            <key>ch_params[ZooKeeperHardwareExceptions]</key>
          </item>
        </graph_item>
        <graph_item>
          <sortorder>1</sortorder>
          <color>2774A4</color>
          <yaxisside>RIGHT</yaxisside>
          <item>
            <host>Clickhouse</host>
            <key>ch_params[ZooKeeperWatch]</key>
          </item>
        </graph_item>
        <graph_item>
          <sortorder>2</sortorder>
          <color>CC0000</color>
          <item>
            <host>Clickhouse</host>
            <key>ch_params[ZooKeeperOtherExceptions]</key>
          </item>
        </graph_item>
        <graph_item>
          <sortorder>3</sortorder>
          <color>CC0000</color>
          <item>
            <host>Clickhouse</host>
            <key>ch_params[ZooKeeperUserExceptions]</key>
          </item>
        </graph_item>
      </graph_items>
    </graph>
  </graphs>
</zabbix_export>